apiVersion: apps.kubeblocks.io/v1
kind: ComponentDefinition
metadata:
  name: {{ include "dataNodeComponentDef" . }}
  labels:
    {{- include "hadoop.labels" . | nindent 4 }}
  annotations:
    {{- include "hadoop.annotations" . | nindent 4 }}
spec:
  provider: kubeblocks
  description: {{ .Chart.Description }}
  serviceVersion: {{ .Chart.AppVersion }}
  serviceKind: hdfs-datanode
  podManagementPolicy: Parallel
  runtime:
    initContainers:
      - name: init-jmx-exporter
        volumeMounts:
          - name: data
            mountPath: /hadoop
        {{- include "hadoop.initJmxExporterContainer" . | nindent 8 }}
      - name: init-kubectl
        command:
          - sh
          - -c
          - |
            cp -r /opt/bitnami/kubectl/bin/kubectl /hadoop/kubectl
        imagePullPolicy: {{ default "IfNotPresent" .Values.images.pullPolicy }}
        volumeMounts:
          - name: data
            mountPath: /hadoop
    containers:
      - name: hdfs-datanode
        imagePullPolicy: {{ default "IfNotPresent" .Values.images.pullPolicy }}
        command:
          - /bin/bash
          - -c
          - |
            /kubeblocks/scripts/start-datanode.sh
        env:
          - name: DEBUG_MODEL
            value: "false"
          - name: HOST_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
        ports:
          - containerPort: 9866
            name: data
          - containerPort: 9864
            name: http
          - containerPort: 9867
            name: ipc
          - containerPort: {{ .Values.jmxExporterPort }}
            name: jmx-exporter
        livenessProbe:
          failureThreshold: 6
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
          exec:
            command:
              - /bin/bash
              - /kubeblocks/scripts/check-data-status.sh
        readinessProbe:
          failureThreshold: 6
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
          exec:
            command:
              - /bin/bash
              - /kubeblocks/scripts/check-data-status.sh
        volumeMounts:
          - name: hadoop-core-config
            mountPath: /hadoop/conf/core-site.xml
            subPath: core-site.xml
          - name: datanode-config
            mountPath: /hadoop/conf/hdfs-site.xml
            subPath: hdfs-site.xml
          - mountPath: /hadoop/conf/log4j.properties
            name: datanode-config
            subPath: log4j.properties
          - name: data
            mountPath: /hadoop
          - name: scripts
            mountPath: /kubeblocks/scripts
          - name: datanode-config
            mountPath: /hadoop/conf/jmx-exporter.yaml
            subPath: jmx-exporter.yaml
        securityContext:
          runAsUser: 0
          runAsGroup: 0
          runAsNonRoot: false
        #  privileged: false
        #  allowPrivilegeEscalation: false
        #  capabilities:
        #    drop: [ "ALL" ]
        #  seccompProfile:
        #    type: "RuntimeDefault"
    securityContext:
      fsGroupChangePolicy: Always
      fsGroup: 1000
    updateStrategy: BestEffortParallel
    volumes:
      - name: hadoop-common
        emptyDir: {}
  configs:
    - name: config
      namespace: {{ .Release.Namespace }}
      template: hadoop-datanode-config-template
      volumeName: datanode-config
      defaultMode: 0755
      # externalManaged: true
      restartOnFileChange: true
  scripts:
    - name: {{ include "hadoop.name" . }}-scripts
      template: {{ include "hadoop.name" . }}-scripts
      volumeName: scripts
      namespace: {{ .Release.Namespace }}
      defaultMode: 0755
  hostNetwork:
    containerPorts:
      - container: hdfs-datanode
        ports:
          - data
          - http
          - ipc
          - jmx-exporter
  vars:
    - name: DATANODE_DATA_HOST_PORT
      valueFrom:
        hostNetworkVarRef:
          optional: true
          container:
            name: hdfs-datanode
            port:
              name: data
              option: Required
    - name: DATANODE_DATA_PORT
      value: "9866"
      expression: {{ `{{if ne (index . "DATANODE_DATA_HOST_PORT") ""}}{{.DATANODE_DATA_HOST_PORT}}{{else}}{{.DATANODE_DATA_PORT}}{{end}}` | toYaml }}
    - name: DATANODE_HTTP_HOST_PORT
      valueFrom:
        hostNetworkVarRef:
          optional: true
          container:
            name: hdfs-datanode
            port:
              name: http
              option: Required
    - name: DATANODE_HTTP_PORT
      value: "9864"
      expression: {{ `{{if ne (index . "DATANODE_HTTP_HOST_PORT") ""}}{{.DATANODE_HTTP_HOST_PORT}}{{else}}{{.DATANODE_HTTP_PORT}}{{end}}` | toYaml }}
    - name: DATANODE_IPC_HOST_PORT
      valueFrom:
        hostNetworkVarRef:
          optional: true
          container:
            name: hdfs-datanode
            port:
              name: ipc
              option: Required
    - name: DATANODE_IPC_PORT
      value: "9867"
      expression: {{ `{{if ne (index . "DATANODE_IPC_HOST_PORT") ""}}{{.DATANODE_IPC_HOST_PORT}}{{else}}{{.DATANODE_IPC_PORT}}{{end}}` | toYaml }}
    - name: DATANODE_JMX_HOST_PORT
      valueFrom:
        hostNetworkVarRef:
          optional: true
          container:
            name: hdfs-datanode
            port:
              name: jmx-exporter
              option: Required
    - name: ENABLE_JMX_EXPORTER
      value: {{ .Values.enableJmxExporter | quote }}
    - name: JMX_EXPORTER_PORT
      value: "{{ .Values.jmxExporterPort }}"
      expression: {{ `{{if ne (index . "DATANODE_JMX_HOST_PORT") ""}}{{.DATANODE_JMX_HOST_PORT}}{{else}}{{.JMX_EXPORTER_PORT}}{{end}}` | toYaml }}
    - name: HOME
      value: /home/hadoop
    - name: CLUSTER_DOMAIN
      value: {{ .Values.clusterDomain | default "cluster.local" }}
    - name: NAMENODE_COMPONENT_REPLICAS
      valueFrom:
        componentVarRef:
          optional: false
          replicas: Required
          compDef: hadoop-hdfs-namenode
    - name: CLUSTER_NAME
      valueFrom:
        clusterVarRef:
          clusterName: Required
    - name: CLUSTER_NAMESPACE
      valueFrom:
        clusterVarRef:
          namespace: Required
    - name: COMPONENT_NAME
      valueFrom:
        componentVarRef:
          optional: false
          shortName: Required
    - name: NAMENODE_CLUSTER_COMPONENT_NAME
      valueFrom:
        componentVarRef:
          compDef: hadoop-hdfs-namenode
          optional: false
          componentName: Required
  policyRules:
    - apiGroups:
        - ""
      resources:
        - configmaps
      verbs:
        - get
        - list
        - patch
        - update
  lifecycleActions:
    memberLeave:
      exec:
        command:
          - bash
          - -c
          - |
            /kubeblocks/scripts/datanode-memberleave.sh
        targetPodSelector: Any
        container: hdfs-datanode