apiVersion: apps.kubeblocks.io/v1
kind: ComponentDefinition
metadata:
  name: {{ include "kafka-controller.componentDefName" . }}
  labels:
    {{- include "kafka.labels" . | nindent 4 }}
    {{- if .Values.commonLabels }}
    {{- include "common.tplvalues.render" ( dict "value" .Values.commonLabels "context" $ ) | nindent 4 }}
    {{- end }}
  annotations:
    {{- include "kafka.annotations" . | nindent 4 }}
    {{- if .Values.commonAnnotations }}
    {{- include "common.tplvalues.render" ( dict "value" .Values.commonAnnotations "context" $ ) | nindent 4 }}
    {{- end }}
spec:
  provider: kubeblocks
  description: Kafka controller that act as controllers (kraft) only server.
  serviceKind: kafka-controller
  serviceVersion: {{ .Values.defaultServiceVersion.controller }}
  vars:
    - name: CLUSTER_UID
      valueFrom:
        clusterVarRef:
          clusterUID: Required
    - name: POD_FQDN_LIST
      valueFrom:
        componentVarRef:
          optional: false
          podFQDNs: Required
    - name: POD_NAME_LIST
      valueFrom:
        componentVarRef:
          optional: false
          podNames: Required
    - name: COMPONENT_NAME
      valueFrom:
        componentVarRef:
          optional: false
          componentName: Required
  ## serial is not used because rsm currently does not support kafka's role detection. The lack of role label during restart will affect the pod restart.
  updateStrategy: BestEffortParallel
  configs:
    - name: kafka-configuration-tpl
      constraintRef: {{ include "kafka.configConstraintName" . }}
      templateRef: {{ include "kafka.configurationTplName" . }}
      volumeName: kafka-config
      namespace: {{ .Release.Namespace }}
    - name: kafka-jmx-configuration-tpl
      templateRef: {{ include "kafka.jmxConfigurationTplName" . }}
      volumeName: jmx-config
      namespace: {{ .Release.Namespace }}
  scripts:
    - name: kafka-scripts-tpl
      templateRef: {{ include "kafka.serverScriptsTplName" . }}
      volumeName: scripts
      namespace: {{ .Release.Namespace }}
      defaultMode: 0755
  runtime:
    securityContext:
      fsGroup: 1001
    containers:
      - name: kafka
        image: {{ .Values.images.registry | default "docker.io" }}/{{ .Values.images.kafka.repository }}:{{ default .Chart.AppVersion .Values.images.kafka.tag }}
        imagePullPolicy: {{ default "IfNotPresent" .Values.images.pullPolicy }}
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
          runAsUser: 1001
        command:
          - /scripts/kafka-server-setup.sh
        env:
          - name: BITNAMI_DEBUG
            value: {{ .Values.debugEnabled | quote }}
          - name: MY_POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: KAFKA_ENABLE_KRAFT
            value: "yes"
          - name: KAFKA_CFG_PROCESS_ROLES
            value: "controller"
          - name: KAFKA_CFG_CONTROLLER_LISTENER_NAMES # required for KRaft
            value: "CONTROLLER"
          - name: KAFKA_CFG_LISTENERS # required for KRaft
            value: "CONTROLLER://:9093"
          - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
            value: "CONTROLLER:PLAINTEXT"
          - name: ALLOW_PLAINTEXT_LISTENER
            value: "yes"
          - name: JMX_PORT
            value: "5555"
          - name: KAFKA_VOLUME_DIR
            value: "/bitnami/kafka"
          - name: KAFKA_CFG_METADATA_LOG_DIR
            value: "/bitnami/kafka/metadata"
          - name: KAFKA_LOG_DIR
            value: "/bitnami/kafka/data"
          - name: KAFKA_HEAP_OPTS
            #value: "-Xmx1024m -Xms1024m"
            value: "-XshowSettings:vm -XX:MaxRAMPercentage=100 -Ddepth=64"
          - name: SERVER_PROP_FILE
            value: /scripts/server.properties
          - name: KAFKA_KRAFT_CLUSTER_ID
            value: $(CLUSTER_UID)
        ports:
          - name: kafka-ctrlr
            containerPort: 9093
        livenessProbe:
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
          tcpSocket:
            port: kafka-ctrlr
        startupProbe:
          failureThreshold: 30
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
          tcpSocket:
            port: kafka-ctrlr
        volumeMounts:
          - name: metadata
            mountPath: /bitnami/kafka
          - name: kafka-config
            mountPath: /scripts/server.properties
            subPath: server.properties
          - name: scripts
            mountPath: /scripts/kafka-server-setup.sh
            subPath: kafka-server-setup.sh
          - name: scripts
            mountPath: /scripts/common.sh
            subPath: common.sh
          - name: scripts
            mountPath: /opt/bitnami/scripts/kafka-env.sh
            subPath: kafka-env.sh
      - name: jmx-exporter
        image: {{ .Values.images.registry | default "docker.io" }}/{{ .Values.images.jmxExporter.repository }}:{{ .Values.images.jmxExporter.tag }}
        imagePullPolicy: {{ default "IfNotPresent" .Values.images.pullPolicy }}
        securityContext:
          runAsNonRoot: true
          runAsUser: 1001
        command:
          - java
        args:
          - -XX:MaxRAMPercentage=100
          - -XshowSettings:vm
          - -jar
          - jmx_prometheus_httpserver.jar
          - "5556"
          - /etc/jmx-kafka/jmx-kafka-prometheus.yml
        ports:
          - name: metrics
            containerPort: 5556
        volumeMounts:
          - name: jmx-config
            mountPath: /etc/jmx-kafka
        env:
          - name: SERVICE_PORT
            value: "5556"
