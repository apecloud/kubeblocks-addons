apiVersion: apps.kubeblocks.io/v1alpha1
kind: ComponentDefinition
metadata:
  name: {{ include "kafka-combine.componentDefName" . }}
  labels:
    {{- include "kafka.labels" . | nindent 4 }}
    {{- if .Values.commonLabels }}
    {{- include "common.tplvalues.render" ( dict "value" .Values.commonLabels "context" $ ) | nindent 4 }}
    {{- end }}
  {{- if .Values.commonAnnotations }}
  annotations: {{- include "common.tplvalues.render" ( dict "value" .Values.commonAnnotations "context" $ ) | nindent 4 }}
  {{- end }}
spec:
  services:
    - name: broker-nodeport
      serviceName: broker-nodeport
      podService: true 
      disableAutoProvision: true
      spec:
        type: NodePort
        ports:
          - name: broker
            port: 9092
            targetPort: kafka-client
  vars:
    - name: SUPER_USER
      valueFrom:
        credentialVarRef:
          name: admin
          username: Required
          optional: false
      ## if the kafka NodePort type Service with name suffix broker-{0,1...} is set, the BROKER_NODE_PORT_{0,1...} will be available
    - name: BROKER_NODE_PORT
      valueFrom:
        serviceVarRef:
          compDef: kafka-combine
          name: broker-nodeport
          optional: true
          port:
            name: broker
            option: Optional
  provider: kubeblocks
  description: |-
    Kafka servers that act as both brokers and controllers are referred to as "combined" servers. Combined servers
    are simpler to operate for small use cases like a development environment. Combined mode is not recommended in critical
    deployment environments.
  serviceKind: kafka
  serviceVersion: {{ .Values.componentServiceVersion.combine }}
  systemAccounts:
    - name: client
      secretRef:
        name: {{ include "kafka.name" . }}-client-secret
        namespace: {{ .Release.Namespace }}
    - name: admin
      secretRef:
        name: {{ include "kafka.name" . }}-superusers-secret
        namespace: {{ .Release.Namespace }}
  ## serial is not used because rsm currently does not support kafka's role detection. The lack of role label during restart will affect the pod restart.
  updateStrategy: BestEffortParallel
  monitor:
    builtIn: false
    exporterConfig:
      scrapePath: /metrics
      scrapePort: 5556
  configs:
    - name: kafka-configuration-tpl
      constraintRef: {{ include "kafka.name" . }}-cc
      templateRef: {{ include "kafka.name" . }}-configuration-tpl
      volumeName: kafka-config
      namespace: {{ .Release.Namespace }}
    - name: {{ include "kafka.name" . }}-jmx-configuration-tpl
      templateRef: {{ include "kafka.name" . }}-jmx-configuration-tpl
      volumeName: jmx-config
      namespace: {{ .Release.Namespace }}
  scripts:
    - name: kafka-scripts-tpl
      templateRef: {{ include "kafka.name" . }}-server-scripts-tpl
      volumeName: scripts
      namespace: {{ .Release.Namespace }}
      defaultMode: 0755
    - name: kafka-scripts-tools-tpl
      templateRef: {{ include "kafka.name" . }}-scripts-tools-tpl
      volumeName: tools
      namespace: {{ .Release.Namespace }}
      defaultMode: 0755
  runtime:
    securityContext:
      fsGroup: 1001
    containers:
      - name: kafka
        image: {{ .Values.images.registry | default "docker.io" }}/{{ .Values.images.kafka.repository }}:{{ default .Chart.AppVersion .Values.images.kafka.tag }}
        imagePullPolicy: {{ default "IfNotPresent" .Values.images.pullPolicy }}
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
          runAsUser: 1001
        command:
          - /scripts/kafka-server-setup.sh
        env:
          - name: BITNAMI_DEBUG
            value: {{ .Values.debugEnabled | quote }}
          - name: MY_POD_IP
            value: "$(KB_PODIP)"
            # value: "$(KB_POD_IP)"
          - name: MY_POD_NAME
            value: "$(KB_POD_NAME)"
          - name: KAFKA_ENABLE_KRAFT
            value: "yes"
          - name: KAFKA_CFG_PROCESS_ROLES
            value: "broker,controller"
          - name: KAFKA_CFG_CONTROLLER_LISTENER_NAMES # required for KRaft
            value: "CONTROLLER"
          - name: KAFKA_CFG_INTER_BROKER_LISTENER_NAME
            value: "INTERNAL"
          - name: KAFKA_CFG_LISTENERS # required for KRaft
            value: "CONTROLLER://:9093,INTERNAL://:9094,CLIENT://:9092"
          - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
            value: "CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT"
          - name: KAFKA_CFG_ADVERTISED_LISTENERS
            #value: "INTERNAL://$(KB_POD_NAME).$(KB_CLUSTER_COMP_NAME)-headless.$(KB_NAMESPACE).svc:9094,CLIENT://$(KB_POD_NAME).$(KB_CLUSTER_COMP_NAME)-headless.$(KB_NAMESPACE).svc:9092"
            value: "INTERNAL://$(KB_POD_IP):9094,CLIENT://$(KB_POD_IP):9092"
          - name: KAFKA_CFG_INITIAL_BROKER_REGISTRATION_TIMEOUT_MS
            value: "240000"
          - name: ALLOW_PLAINTEXT_LISTENER
            value: "yes"
          - name: JMX_PORT
            value: "5555"
          - name: KAFKA_VOLUME_DIR
            value: "/bitnami/kafka"
          - name: KAFKA_CFG_METADATA_LOG_DIR
            value: "/bitnami/kafka/metadata"
          - name: KAFKA_LOG_DIR
            value: "/bitnami/kafka/data"
          - name: KAFKA_HEAP_OPTS
            #value: "-Xmx1024m -Xms1024m"
            value: "-XshowSettings:vm -XX:MaxRAMPercentage=100 -Ddepth=64"
          - name: SERVER_PROP_FILE
            value: /scripts/server.properties
          - name: KAFKA_KRAFT_CLUSTER_ID
            value: $(KB_CLUSTER_UID)
          - name: KAFKA_CFG_SUPER_USERS
            value: "User:$(SUPER_USER)"
          # - name: KB_KAFKA_ENABLE_SASL  # enable the SASL with plain mode
          # value: "false"
          - name: KB_KAFKA_SASL_CONFIG_PATH  # specify the SASL jaas users
            value: /tools/server-jaas.properties
        ports:
          - name: kafka-client
            containerPort: 9092
          - name: kafka-ctrlr
            containerPort: 9093
          - name: kafka-internal
            containerPort: 9094
        livenessProbe:
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
          tcpSocket:
            port: kafka-ctrlr
        startupProbe:
          failureThreshold: 30
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
          tcpSocket:
            port: kafka-ctrlr
        volumeMounts:
          - name: data
            mountPath: /bitnami/kafka
          - name: metadata
            mountPath: /bitnami/kafka/metadata
          - name: scripts
            mountPath: /scripts/kafka-server-setup.sh
            subPath: kafka-server-setup.sh
          - name: kafka-config
            mountPath: /scripts/server.properties
            subPath: server.properties
          - name: tools
            mountPath: /tools/client-ssl.properties
            subPath: client-ssl.properties
          - name: tools
            mountPath: /tools/server-jaas.properties
            subPath: server-jaas.properties
      - name: jmx-exporter
        image: {{ .Values.images.registry | default "docker.io" }}/{{ .Values.images.jmxExporter.repository }}:{{ .Values.images.jmxExporter.tag }}
        imagePullPolicy: {{ default "IfNotPresent" .Values.images.pullPolicy }}
        securityContext:
          runAsNonRoot: true
          runAsUser: 1001
        command:
          - java
        args:
          - -XX:MaxRAMPercentage=100
          - -XshowSettings:vm
          - -jar
          - jmx_prometheus_httpserver.jar
          - "5556"
          - /etc/jmx-kafka/jmx-kafka-prometheus.yml
        ports:
          - name: metrics
            containerPort: 5556
        env:
          - name: SERVICE_PORT
            value: "5556"
        volumeMounts:
          - name: jmx-config
            mountPath: /etc/jmx-kafka
