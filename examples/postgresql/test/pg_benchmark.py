#!/usr/bin/env python3
"""
################################################################################
#                     PostgreSQL Sysbench Benchmark Test Suite
################################################################################
#
# ü§ñ This benchmark test was generated by GPT (Claude Sonnet 4) to provide
#    comprehensive PostgreSQL performance testing using sysbench.
#
# üìã DESCRIPTION:
#    A professional-grade benchmark testing tool that measures PostgreSQL
#    performance across multiple dimensions:
#    - OLTP read/write mixed workloads
#    - Read-only and write-only performance
#    - Query latency and throughput analysis
#    - Thread scaling and concurrency testing
#    - Connection handling under load
#
# üîß PREREQUISITES:
#    - Python 3.6 or higher
#    - PostgreSQL server (any recent version)
#    - PostgreSQL client tools (psql) installed and in PATH
#    - Sysbench with PostgreSQL support installed
#    - Admin access to PostgreSQL server for creating test databases
#
# üì¶ INSTALLATION (Ubuntu/Debian):
#    sudo apt-get update
#    sudo apt-get install postgresql-client sysbench python3
#
# üì¶ INSTALLATION (CentOS/RHEL):
#    sudo yum install postgresql sysbench python3
#
# üì¶ INSTALLATION (macOS):
#    brew install postgresql sysbench python3
#
# üöÄ BASIC USAGE:
#    python3 pg_benchmark.py --host localhost --user postgres --password mypass
#
# üéØ ADVANCED USAGE EXAMPLES:
#
#    # Quick test with small dataset
#    python3 pg_benchmark.py --host localhost --user postgres --password mypass \
#                           --table-size 10000 --duration 30 --threads 1 4 8
#
#    # High-performance test with large dataset
#    python3 pg_benchmark.py --host remotehost --user admin --password secret \
#                           --table-size 1000000 --duration 300 --threads 1 2 4 8 16 32 64
#
#    # Remote database testing
#    python3 pg_benchmark.py --host 192.168.1.100 --port 5432 --user dbadmin \
#                           --password strongpass --database production_replica
#
# üìä WHAT IT MEASURES:
#    ‚úÖ Connection performance and stability
#    ‚úÖ Transactions per second (TPS) under various loads
#    ‚úÖ Query latency (average, min, max, 95th percentile)
#    ‚úÖ Thread scaling efficiency and optimal concurrency
#    ‚úÖ Mixed OLTP workload performance (reads + writes)
#    ‚úÖ Specialized workload performance (read-only, write-only)
#    ‚úÖ Random point select performance
#    ‚úÖ Range scan performance
#    ‚úÖ Error rates and connection failures
#
# üìà OUTPUT:
#    - Real-time progress with emoji indicators
#    - Comprehensive console report with key metrics
#    - JSON file export with detailed results for analysis
#    - Thread scaling analysis and efficiency metrics
#    - Performance comparison across different workload types
#
# üóÇÔ∏è TEST DATABASE:
#    The benchmark automatically creates a temporary test database
#    'sysbench_test' and user 'sysbench_user'. All test data is cleaned
#    up automatically after completion.
#
# ‚ö†Ô∏è  SAFETY NOTES:
#    - Only creates temporary test databases, doesn't affect existing data
#    - Requires admin privileges to create databases and users
#    - Test database is automatically cleaned up after benchmark
#    - Safe to run on production servers (creates isolated test environment)
#
# üèÜ PERFORMANCE TIPS:
#    - Use SSD storage for better IOPS performance
#    - Tune PostgreSQL shared_buffers and work_mem for your hardware
#    - Monitor system resources (CPU, memory, disk I/O) during tests
#    - Run multiple iterations and compare results for consistency
#    - Test with thread counts matching your expected concurrent users
#
# üìÑ GENERATED REPORTS:
#    - Console output: Real-time results with summary statistics
#    - JSON file: postgresql_sysbench_YYYYMMDD_HHMMSS.json with detailed metrics
#    - Metrics include: TPS, latency percentiles, error counts, scaling efficiency
#
# üêõ TROUBLESHOOTING:
#    - "psql: command not found" ‚Üí Install postgresql-client package
#    - "sysbench: command not found" ‚Üí Install sysbench package
#    - Connection failures ‚Üí Check host, port, credentials, and firewall
#    - Permission denied ‚Üí Ensure user has CREATE DATABASE privileges
#
# üìû SUPPORT:
#    This tool was generated by AI and is provided as-is. For PostgreSQL
#    performance tuning, consult the official PostgreSQL documentation
#    and performance guides.
#
################################################################################

A comprehensive benchmark testing tool for PostgreSQL that measures:
- Connection performance
- CRUD operations throughput
- Concurrent connection handling
- Query performance under load
- Transaction performance

Requirements:
- Python 3.6+
- PostgreSQL client (psql)
- Sysbench with PostgreSQL support
- Standard Python libraries only

Usage:
    python3 pg_benchmark.py --host localhost --user postgres --password mypass
"""

import subprocess
import argparse
import time
import json
import os
import sys
import re
import statistics
from datetime import datetime


class PostgreSQLSysbench:
    def __init__(self, host, port, user, password, database="postgres"):
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.database = database
        self.test_db = "sysbench_test"
        self.test_user = "sysbench_user"
        self.test_password = "SysbenchPass123!"
        self.results = {}

    def _run_sql(self, sql_command, database=None, capture_output=True, timeout=30):
        """Execute SQL command using psql"""
        db = database or self.database
        env = os.environ.copy()
        env['PGPASSWORD'] = self.password

        cmd = [
            'psql',
            '-h', self.host,
            '-p', str(self.port),
            '-U', self.user,
            '-d', db,
            '-c', sql_command,
            '-t',  # tuples only
            '-A',  # unaligned output
        ]

        try:
            result = subprocess.run(
                cmd,
                env=env,
                capture_output=capture_output,
                text=True,
                timeout=timeout,
                check=True
            )
            return True, result.stdout.strip() if capture_output else ""
        except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:
            error_msg = getattr(e, 'stderr', str(e))
            return False, error_msg

    def _run_sysbench(self, test_type, operation, threads=1, duration=60, table_size=100000, additional_params=""):
        """Execute sysbench command with proper error handling"""

        base_cmd = [
            'sysbench',
            test_type,
            f'--db-driver=pgsql',
            f'--pgsql-host={self.host}',
            f'--pgsql-port={self.port}',
            f'--pgsql-user={self.test_user}',
            f'--pgsql-password={self.test_password}',
            f'--pgsql-db={self.test_db}',
            f'--table-size={table_size}',
            f'--report-interval=10',
        ]

        if operation == "run":
            base_cmd.extend([
                f'--threads={threads}',
                f'--time={duration}',
            ])

        if additional_params:
            base_cmd.extend(additional_params.split())

        base_cmd.append(operation)

        try:
            print(f"üîÑ Running sysbench {test_type} {operation}...")
            if threads > 1:
                print(f"   Threads: {threads}, Duration: {duration}s")

            result = subprocess.run(
                base_cmd,
                capture_output=True,
                text=True,
                check=True,
                timeout=duration + 60 if operation == "run" else 120
            )

            print(f"‚úÖ Sysbench {test_type} {operation} completed successfully")
            return True, result.stdout

        except subprocess.CalledProcessError as e:
            print(f"‚ùå Error during sysbench {test_type} {operation}:")
            print(f"   Command: {' '.join(base_cmd)}")
            print(f"   Error: {e.stderr}")
            return False, e.stderr
        except subprocess.TimeoutExpired:
            print(f"‚è∞ Sysbench {test_type} {operation} timed out")
            return False, "Command timed out"

    def _parse_sysbench_results(self, output):
        """Parse sysbench output to extract key metrics"""
        results = {}

        # Extract key metrics using regex
        patterns = {
            'transactions': r'transactions:\s+(\d+)\s+\(([0-9.]+)\s+per sec\.\)',
            'queries': r'queries:\s+(\d+)\s+\(([0-9.]+)\s+per sec\.\)',
            'latency_min': r'min:\s+([0-9.]+)ms',
            'latency_avg': r'avg:\s+([0-9.]+)ms',
            'latency_max': r'max:\s+([0-9.]+)ms',
            'latency_95th': r'95th percentile:\s+([0-9.]+)ms',
            'errors': r'errors:\s+(\d+)',
            'reconnects': r'reconnects:\s+(\d+)',
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, output)
            if match:
                if 'transactions' in key or 'queries' in key:
                    results[key + '_total'] = int(match.group(1))
                    results[key + '_per_sec'] = float(match.group(2))
                else:
                    results[key] = float(match.group(1)) if '.' in match.group(1) else int(match.group(1))

        return results

    def check_dependencies(self):
        """Check if required dependencies are installed"""
        print("üîç Checking dependencies...")

        dependencies = [
            ("psql", ["psql", "--version"], "PostgreSQL client (psql) is required"),
            ("sysbench", ["sysbench", "--version"], "Sysbench is required for benchmarking")
        ]

        for name, cmd, error_msg in dependencies:
            try:
                result = subprocess.run(cmd, check=True, capture_output=True, text=True)
                version = result.stdout.split('\n')[0]
                print(f"‚úÖ {name}: {version}")
            except (subprocess.CalledProcessError, FileNotFoundError):
                print(f"‚ùå Error: {error_msg}")
                if name == "sysbench":
                    print("Installation instructions:")
                    print("  Ubuntu/Debian: sudo apt-get install sysbench")
                    print("  CentOS/RHEL: sudo yum install sysbench")
                    print("  macOS: brew install sysbench")
                elif name == "psql":
                    print("Installation instructions:")
                    print("  Ubuntu/Debian: sudo apt-get install postgresql-client")
                    print("  CentOS/RHEL: sudo yum install postgresql")
                    print("  macOS: brew install postgresql")
                return False

        return True

    def check_connection(self):
        """Test basic connectivity to PostgreSQL"""
        print("üîå Testing PostgreSQL connection...")

        start_time = time.time()
        success, output = self._run_sql("SELECT version();")
        connection_time = time.time() - start_time

        if success:
            version = output.split('\n')[0] if output else "Unknown"
            print(f"‚úÖ Connected successfully in {connection_time:.3f}s")
            print(f"   Version: {version}")
            self.results['connection'] = {
                'success': True,
                'time': connection_time,
                'version': version
            }
            return True
        else:
            print(f"‚ùå Connection failed: {output}")
            self.results['connection'] = {
                'success': False,
                'error': output
            }
            return False

    def setup_test_environment(self):
        """Create test database and user for sysbench"""
        print("üîß Setting up test environment...")

        # Drop test database if exists
        self._run_sql(f"DROP DATABASE IF EXISTS {self.test_db};")

        # Create test database
        success, output = self._run_sql(f"CREATE DATABASE {self.test_db};")
        if not success:
            print(f"‚ùå Failed to create test database: {output}")
            return False

        # Check if user exists
        success, output = self._run_sql(
            f"SELECT 1 FROM pg_roles WHERE rolname = '{self.test_user}';",
            capture_output=True
        )

        # Create user if it doesn't exist
        if not output.strip():
            success, output = self._run_sql(
                f"CREATE USER {self.test_user} WITH PASSWORD '{self.test_password}';",
                capture_output=False
            )
            if not success:
                print(f"‚ùå Failed to create test user: {output}")
                return False
            print(f"‚úÖ Created user {self.test_user}")
        else:
            print(f"üìã User {self.test_user} already exists")

        # Grant privileges
        success, _ = self._run_sql(
            f"GRANT ALL PRIVILEGES ON DATABASE {self.test_db} TO {self.test_user};",
            capture_output=False
        )
        if not success:
            return False

        success, _ = self._run_sql(
            f"ALTER DATABASE {self.test_db} OWNER TO {self.test_user};",
            capture_output=False
        )
        if not success:
            return False

        print("‚úÖ Test environment setup completed successfully")
        return True

    def run_benchmark_suite(self, table_size=100000, duration=60, thread_counts=[1, 4, 8, 16]):
        """Run comprehensive sysbench benchmark suite"""
        print(f"üöÄ Starting PostgreSQL Sysbench Benchmark Suite")
        print(f"   Table size: {table_size:,} rows")
        print(f"   Test duration: {duration}s per test")
        print(f"   Thread counts: {thread_counts}")
        print("="*60)

        # Test configurations
        test_configs = [
            ("oltp_read_write", "Mixed OLTP Read/Write"),
            ("oltp_read_only", "Read-Only OLTP"),
            ("oltp_write_only", "Write-Only OLTP"),
            ("select_random_points", "Random Point Selects"),
            ("select_random_ranges", "Random Range Selects"),
        ]

        benchmark_results = {}

        for test_type, description in test_configs:
            print(f"\nüìä {description} Benchmark")
            print("-" * 40)

            # Prepare test data
            success, output = self._run_sysbench(test_type, "prepare", table_size=table_size)
            if not success:
                print(f"‚ö†Ô∏è  Failed to prepare {test_type}, skipping...")
                continue

            test_results = {}

            # Run tests with different thread counts
            for threads in thread_counts:
                print(f"\nüîπ Testing with {threads} thread(s)...")

                success, output = self._run_sysbench(
                    test_type, "run",
                    threads=threads,
                    duration=duration,
                    table_size=table_size
                )

                if success:
                    parsed_results = self._parse_sysbench_results(output)
                    test_results[f"{threads}_threads"] = parsed_results

                    # Print key metrics
                    if 'transactions_per_sec' in parsed_results:
                        print(f"   TPS: {parsed_results['transactions_per_sec']:.2f}")
                    if 'latency_avg' in parsed_results:
                        print(f"   Avg Latency: {parsed_results['latency_avg']:.2f}ms")
                    if 'latency_95th' in parsed_results:
                        print(f"   95th Latency: {parsed_results['latency_95th']:.2f}ms")
                else:
                    print(f"   ‚ùå Test failed with {threads} threads")
                    test_results[f"{threads}_threads"] = {"error": output}

            benchmark_results[test_type] = {
                'description': description,
                'results': test_results
            }

            # Cleanup after each test
            self._run_sysbench(test_type, "cleanup", table_size=table_size)

        self.results['benchmark_suite'] = benchmark_results
        return benchmark_results

    def run_custom_workload(self, test_type="oltp_read_write", table_size=100000,
                          duration=300, max_threads=32):
        """Run a custom workload with scaling thread analysis"""
        print(f"\nüéØ Custom Workload Analysis: {test_type}")
        print(f"   Duration: {duration}s, Max threads: {max_threads}")
        print("="*50)

        # Prepare test data
        success, output = self._run_sysbench(test_type, "prepare", table_size=table_size)
        if not success:
            print(f"‚ùå Failed to prepare {test_type}")
            return False

        # Thread scaling test: 1, 2, 4, 8, 16, 32...
        thread_counts = []
        threads = 1
        while threads <= max_threads:
            thread_counts.append(threads)
            threads *= 2

        scaling_results = {}

        for threads in thread_counts:
            print(f"\nüìà Testing scalability with {threads} threads...")

            success, output = self._run_sysbench(
                test_type, "run",
                threads=threads,
                duration=duration,
                table_size=table_size
            )

            if success:
                parsed_results = self._parse_sysbench_results(output)
                scaling_results[threads] = parsed_results

                tps = parsed_results.get('transactions_per_sec', 0)
                latency = parsed_results.get('latency_avg', 0)

                print(f"   üìä TPS: {tps:.2f}, Latency: {latency:.2f}ms")

                # Calculate efficiency (TPS per thread)
                efficiency = tps / threads if threads > 0 else 0
                print(f"   üìà Efficiency: {efficiency:.2f} TPS/thread")
            else:
                print(f"   ‚ùå Failed with {threads} threads")
                scaling_results[threads] = {"error": output}

        # Cleanup
        self._run_sysbench(test_type, "cleanup", table_size=table_size)

        self.results['custom_workload'] = {
            'test_type': test_type,
            'scaling_results': scaling_results
        }

        return True

    def cleanup(self):
        """Clean up test database and user"""
        print("üßπ Cleaning up test environment...")

        # Drop test database
        success, _ = self._run_sql(f"DROP DATABASE IF EXISTS {self.test_db};")
        if success:
            print("‚úÖ Test database cleaned up successfully")
        else:
            print("‚ö†Ô∏è  Warning: Could not clean up test database")

        # Note: We don't drop the user as it might be used by other tests

    def generate_report(self):
        """Generate a comprehensive benchmark report"""
        print("\n" + "="*80)
        print("üìã POSTGRESQL SYSBENCH BENCHMARK REPORT")
        print("="*80)
        print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Host: {self.host}:{self.port}")
        print(f"Database: {self.database}")
        print("-"*80)

        # Connection info
        if 'connection' in self.results:
            conn = self.results['connection']
            print(f"Connection Test: {'‚úÖ PASS' if conn['success'] else '‚ùå FAIL'}")
            if conn['success']:
                print(f"  Connection Time: {conn['time']:.3f}s")
                print(f"  PostgreSQL Version: {conn.get('version', 'Unknown')}")

        # Benchmark suite results
        if 'benchmark_suite' in self.results:
            print(f"\nüìä BENCHMARK SUITE RESULTS")
            print("-" * 40)

            for test_type, test_data in self.results['benchmark_suite'].items():
                print(f"\nüîπ {test_data['description']}:")

                # Find best performance across thread counts
                best_tps = 0
                best_threads = 0

                for thread_config, results in test_data['results'].items():
                    if 'error' not in results and 'transactions_per_sec' in results:
                        tps = results['transactions_per_sec']
                        threads = int(thread_config.split('_')[0])

                        if tps > best_tps:
                            best_tps = tps
                            best_threads = threads

                        print(f"  {threads:2d} threads: {tps:8.2f} TPS, "
                              f"{results.get('latency_avg', 0):6.2f}ms avg latency")

                if best_tps > 0:
                    print(f"  üèÜ Best: {best_tps:.2f} TPS with {best_threads} threads")

        # Custom workload results
        if 'custom_workload' in self.results:
            custom = self.results['custom_workload']
            print(f"\nüéØ CUSTOM WORKLOAD ANALYSIS")
            print(f"Test Type: {custom['test_type']}")
            print("-" * 40)

            thread_counts = sorted(custom['scaling_results'].keys())

            print("Thread Scaling Analysis:")
            print("Threads |    TPS    | Latency(ms) | Efficiency(TPS/thread)")
            print("-" * 60)

            for threads in thread_counts:
                results = custom['scaling_results'][threads]
                if 'error' not in results:
                    tps = results.get('transactions_per_sec', 0)
                    latency = results.get('latency_avg', 0)
                    efficiency = tps / threads if threads > 0 else 0

                    print(f"   {threads:2d}   | {tps:8.2f}  |   {latency:7.2f}   |      {efficiency:6.2f}")

        print("\n" + "="*80)

        # Save detailed results to JSON file
        report_file = f"postgresql_sysbench_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(report_file, 'w') as f:
                json.dump(self.results, f, indent=2, default=str)
            print(f"üìÑ Detailed results saved to: {report_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not save detailed results: {e}")

    def run_full_benchmark(self, table_size=100000, duration=60, thread_counts=[1, 4, 8, 16]):
        """Run the complete benchmark suite"""
        start_time = time.time()

        # Check dependencies
        if not self.check_dependencies():
            return False

        # Check connection
        if not self.check_connection():
            print("‚ùå Cannot proceed without database connection")
            return False

        # Setup test environment
        if not self.setup_test_environment():
            print("‚ùå Cannot proceed without test environment")
            return False

        try:
            # Run benchmark suite
            self.run_benchmark_suite(table_size, duration, thread_counts)

            # Run custom workload analysis
            self.run_custom_workload("oltp_read_write", table_size, duration*2, max(thread_counts)*2)

        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è  Benchmark interrupted by user")
        except Exception as e:
            print(f"\n‚ùå Unexpected error during benchmark: {e}")
        finally:
            # Always cleanup
            self.cleanup()

        total_time = time.time() - start_time
        print(f"\n‚è±Ô∏è  Total benchmark time: {total_time:.1f} seconds")

        # Generate report
        self.generate_report()
        return True


def main():
    parser = argparse.ArgumentParser(
        description='PostgreSQL Sysbench Benchmark Test Suite',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic benchmark
  python3 pg_benchmark.py --host localhost --user postgres --password mypass

  # Custom configuration
  python3 pg_benchmark.py --host 192.168.1.100 --user admin --password secret \\
                         --table-size 1000000 --duration 120 --threads 1 2 4 8 16 32
        """
    )

    parser.add_argument('--host', required=True, help='PostgreSQL host')
    parser.add_argument('--port', type=int, default=5432, help='PostgreSQL port (default: 5432)')
    parser.add_argument('--user', required=True, help='PostgreSQL admin user')
    parser.add_argument('--password', required=True, help='PostgreSQL admin password')
    parser.add_argument('--database', default='postgres', help='Initial database to connect to (default: postgres)')
    parser.add_argument('--table-size', type=int, default=100000, help='Number of rows per table (default: 100000)')
    parser.add_argument('--duration', type=int, default=60, help='Test duration in seconds (default: 60)')
    parser.add_argument('--threads', nargs='+', type=int, default=[1, 4, 8, 16],
                       help='Thread counts to test (default: 1 4 8 16)')

    args = parser.parse_args()

    # Validate thread counts
    if any(t <= 0 for t in args.threads):
        print("‚ùå Error: Thread counts must be positive integers")
        sys.exit(1)

    # Run benchmark
    benchmark = PostgreSQLSysbench(
        args.host, args.port, args.user, args.password, args.database
    )

    success = benchmark.run_full_benchmark(
        table_size=args.table_size,
        duration=args.duration,
        thread_counts=sorted(args.threads)
    )

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()