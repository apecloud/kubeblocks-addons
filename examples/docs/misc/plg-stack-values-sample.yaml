loki:
  enabled: true
  url: http://loki-stack.logging:3100
  image:
    tag: 2.9.3
  persistence:
    enabled: true

promtail:
  enabled: true
  podSecurityContext:
    runAsUser: 0
    runAsGroup: 0
    fsGroup: 0  # add fsGroup to allow promtail to read logs from the host. Set to the group id of the user that has access to the log files
  containerSecurityContext:
    allowPrivilegeEscalation: true
    privileged: true

  extraVolumes:  # mount the local-path-provisioner volume to promtail. Set the path to the directory where the MySQL error logs are stored.
    - name: localpv
      hostPath:
        path: "/var/local-path-provisioner"
    - name: kubelet
      hostPath:
        path: "/var/lib/kubelet/pods"
  extraVolumeMounts:
    - name: localpv
      mountPath: "/var/local-path-provisioner"
      readOnly: true
      mountPropagation: HostToContainer
    - name: kubelet
      mountPath: "/var/lib/kubelet/pods"
      readOnly: true
      mountPropagation: HostToContainer # indicates that any mounts created on the host will be visible inside the container, and any mounts created inside the container will also be visible on the host.

  config:
    logLevel: debug  # set to debug mode in your development environment
    clients:
      - url: http://loki-stack.logging:3100/loki/api/v1/push
    snippets:
      scrapeConfigs: |
        - job_name: mysql-logs
          static_configs:
            - targets:
                - localhost
              labels:
                job: mysql-logs
                __path__: /var/local-path-provisioner/*/log/mysqld-error.log*  # Specify the path pattern for MySQL error logs w.r.t your Storage Provider

          # Define processing stages for the collected logs
          pipeline_stages:
            - match:
                selector: '{job="mysql-logs"}'
                stages:
                  - regex:  # Extract metadata from the log file path using regex, must set source to filename
                      expression: '/var/local-path-provisioner/(?P<pvc_name>pvc-[^_]+)_(?P<namespace>[^_]+)_data-(?P<pod_name>[^/]+)/log/mysqld-error.log.*'
                      source: filename
                  - labels:
                      namespace:
                      pod_name:
            - regex:  # Parse the log line content using regex
                expression: '^(?P<timestamp>[^ ]+) (?P<thread_id>\d+) \[(?P<level>[^\]]+)\] \[(?P<error_code>[^\]]+)\] \[(?P<source>[^\]]+)\] (?P<message>.*)$'
            - timestamp:  # Extract and format the timestamp from the log
                source: timestamp
                format: RFC3339Nano
            - labels:  # Add additional labels from the parsed log content
                level:
                error_code:
            - labeldrop:
              - filename
            - output:  # Define the final output of the log processing
                source: message

        - job_name: mysql-slowlogs
          static_configs:
            - labels:
                job: mysql-slowlogs
                __path__: /var/local-path-provisioner/*/log/mysqld-slowquery.log*
          pipeline_stages:
            - multiline:
                firstline: '#\sTime:.*'
            - regex:
                expression: '#\s*Time:\s*(?P<timestamp>.*)\n#\s*User@Host:\s*(?P<user>[^\[]+).*@\s*(?P<host>.*]).*Id:\s*(?P<id>\d+)\n#\s*Query_time:\s*(?P<query_time>\d+\.\d+)\s*Lock_time:\s*(?P<lock_time>\d+\.\d+)\s*Rows_sent:\s*(?P<rows_sent>\d+)\s*Rows_examined:\s*(?P<rows_examined>\d+)\n(?P<query>(?s:.*))$'
            - labels:
                timestamp:
                user:
                host:
                id:
                query_time:
                lock_time:
                rows_sent:
                rows_examined:
            - drop:
                expression: "^ *$"
                drop_counter_reason: "drop empty lines"
            - labeldrop:
              - filename
            - output:  # Define the final output of the log processing
                source: query

        - job_name: mysql-csi-logs
          static_configs:
            - targets:
                - localhost
              labels:
                job: mysql-csi-logs
                __path__: /var/lib/kubelet/pods/*/volumes/kubernetes.io~csi/*/mount/log/mysqld-error.log*  # Specify the path pattern for MySQL error logs w.r.t your Storage Provider

          # Define processing stages for the collected logs
          pipeline_stages:
            - match:
                selector: '{job="mysql-csi-logs"}'
                stages:
                  - regex:
                      expression: '/var/lib/kubelet/pods/(?P<pod_uid>[^/]+)/volumes/kubernetes.io~csi/(?P<pvc_name>[^/]+)/mount/log/mysqld-error.log.*'
                      source: filename
                  - labels:
                      pod_uid:
                      pvc_name:
            - regex:  # Parse the log line content using regex
                expression: '^(?P<timestamp>[^ ]+) (?P<thread_id>\d+) \[(?P<level>[^\]]+)\] \[(?P<error_code>[^\]]+)\] \[(?P<source>[^\]]+)\] (?P<message>.*)$'
            - timestamp:  # Extract and format the timestamp from the log
                source: timestamp
                format: RFC3339Nano
            - labels:  # Add additional labels from the parsed log content
                level:
                error_code:
            - labeldrop:
              - filename
            - output:  # Define the final output of the log processing
                source: message

        - job_name: mysql-csi-slowlogs
          static_configs:
            - labels:
                job: mysql-csi-slowlogs
                __path__: /var/lib/kubelet/pods/*/volumes/kubernetes.io~csi/*/mount/log/mysqld-slowquery.log*
          pipeline_stages:
            - multiline:
                firstline: '#\sTime:.*'
            - regex:
                expression: '#\s*Time:\s*(?P<timestamp>.*)\n#\s*User@Host:\s*(?P<user>[^\[]+).*@\s*(?P<host>.*]).*Id:\s*(?P<id>\d+)\n#\s*Query_time:\s*(?P<query_time>\d+\.\d+)\s*Lock_time:\s*(?P<lock_time>\d+\.\d+)\s*Rows_sent:\s*(?P<rows_sent>\d+)\s*Rows_examined:\s*(?P<rows_examined>\d+)\n(?P<query>(?s:.*))$'
            - labels:
                timestamp:
                user:
                host:
                id:
                query_time:
                lock_time:
                rows_sent:
                rows_examined:
                query:
            - drop:
                expression: "^ *$"
                drop_counter_reason: "drop empty lines"
            - labeldrop:
              - filename
            - output:  # Define the final output of the log processing
                source: query

        - job_name: mysql-audit-logs
          static_configs:
            - labels:
                job: mysql-audit-logs
                __path__: /var/local-path-provisioner/*/auditlog/audit.log*
          pipeline_stages:
            - match:
                selector: '{job="mysql-audit-logs"}'
                stages:
                  - regex:  # Extract metadata from the log file path using regex, must set source to filename
                      expression: '/var/local-path-provisioner/(?P<pvc_name>pvc-[^_]+)_(?P<namespace>[^_]+)_data-(?P<pod_name>[^/]+)/auditlog/audit.log.*'
                      source: filename
                  - labels:
                      namespace:
                      pod_name:
            - multiline:
                firstline: '^\s*<AUDIT_RECORD'  # Start of a new log entry
                max_wait_time: 3s               # Maximum time to wait for the next line
            - regex:
                expression: '<AUDIT_RECORD\s+NAME="(?P<name>[^"]+)"\s+RECORD="(?P<record>[^"]+)"\s+TIMESTAMP="(?P<timestamp>[^"]+)"\s+COMMAND_CLASS="(?P<command_class>[^"]+)"\s+CONNECTION_ID="(?P<connection_id>[^"]+)"\s+STATUS="(?P<status>[^"]+)"\s+SQLTEXT="(?P<sqltext>[^"]+)"\s+USER="(?P<user>[^"]+)"\s+HOST="(?P<host>[^"]*)"\s+OS_USER="(?P<os_user>[^"]*)"\s+IP="(?P<ip>[^"]*)"\s+DB="(?P<db>[^"]*)"\s*\/>'
            - labels:
                name: name
                record: record
                timestamp: timestamp
                command_class: command_class
                connection_id: connection_id
                status: status
                sqltext: sqltext
                user: user
                host: host
                os_user: os_user
                ip: ip
                db: db

            - labeldrop:
              - filename

            - output:  # Define the final output of the log processing
                source: sqltext